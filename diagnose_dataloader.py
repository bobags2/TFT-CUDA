#!/usr/bin/env python3
"""
DataLoader diagnostic and fix for TFT training.
Tests the data loading pipeline to identify and resolve unpacking issues.
"""

import sys
sys.path.insert(0, 'python')

import numpy as np
import warnings
warnings.filterwarnings('ignore')

try:
    import torch
    from torch.utils.data import DataLoader
    from data import TFTDataset
    TORCH_AVAILABLE = True
except ImportError as e:
    print(f"‚ùå PyTorch/TFT dependencies not available: {e}")
    sys.exit(1)

def diagnose_dataloader():
    """Diagnose DataLoader unpacking issues."""
    print("üîç DataLoader Diagnostic Tool")
    print("=" * 50)
    
    # Check if training data exists
    try:
        X_train = np.load('data/X_train.npy')
        y_train = np.load('data/y_train.npy')
        print(f"‚úì Training data loaded: X{X_train.shape}, y{y_train.shape}")
    except FileNotFoundError:
        print("‚ùå Training data not found. Run training script first to generate data.")
        return False
    
    # Create dataset and dataloader
    try:
        # Use single target
        y_train_single = y_train[:, 0:1]
        
        dataset = TFTDataset(X_train[:100], y_train_single[:100], sequence_length=128, prediction_horizon=1)
        loader = DataLoader(dataset, batch_size=4, shuffle=False)
        print(f"‚úì Dataset created: {len(dataset)} samples")
        print(f"‚úì DataLoader created with batch_size=4")
        
    except Exception as e:
        print(f"‚ùå Dataset/DataLoader creation failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test data loading
    print("\nüß™ Testing DataLoader iterations...")
    
    for batch_idx, batch_item in enumerate(loader):
        print(f"\nBatch {batch_idx}:")
        print(f"  Batch type: {type(batch_item)}")
        
        if isinstance(batch_item, (list, tuple)):
            print(f"  Batch length: {len(batch_item)}")
            for i, item in enumerate(batch_item):
                if hasattr(item, 'shape'):
                    print(f"    Item {i}: {type(item)}, shape={item.shape}")
                elif isinstance(item, dict):
                    print(f"    Item {i}: dict with keys={list(item.keys())}")
                    for k, v in item.items():
                        if hasattr(v, 'shape'):
                            print(f"      {k}: shape={v.shape}")
                else:
                    print(f"    Item {i}: {type(item)}")
        else:
            if hasattr(batch_item, 'shape'):
                print(f"  Single item: {type(batch_item)}, shape={batch_item.shape}")
            elif isinstance(batch_item, dict):
                print(f"  Single dict with keys: {list(batch_item.keys())}")
                for k, v in batch_item.items():
                    if hasattr(v, 'shape'):
                        print(f"    {k}: shape={v.shape}")
            else:
                print(f"  Single item: {type(batch_item)}")
        
        # Test unpacking strategies
        print(f"\n  üîß Testing unpacking strategies:")
        
        try:
            # Strategy 1: Standard tuple unpacking
            inputs, targets = batch_item
            print(f"    ‚úì Strategy 1 (tuple unpacking): SUCCESS")
            print(f"      Inputs type: {type(inputs)}")
            print(f"      Targets type: {type(targets)}, shape: {targets.shape if hasattr(targets, 'shape') else 'N/A'}")
        except Exception as e:
            print(f"    ‚ùå Strategy 1 (tuple unpacking): FAILED - {e}")
        
        try:
            # Strategy 2: List/tuple check
            if isinstance(batch_item, (list, tuple)) and len(batch_item) >= 2:
                inputs, targets = batch_item[0], batch_item[1]
                print(f"    ‚úì Strategy 2 (indexed unpacking): SUCCESS")
                print(f"      Inputs type: {type(inputs)}")
                print(f"      Targets type: {type(targets)}, shape: {targets.shape if hasattr(targets, 'shape') else 'N/A'}")
            else:
                print(f"    ‚ö†Ô∏è  Strategy 2: Not applicable (not a tuple/list with >=2 items)")
        except Exception as e:
            print(f"    ‚ùå Strategy 2 (indexed unpacking): FAILED - {e}")
        
        try:
            # Strategy 3: Flexible unpacking
            if isinstance(batch_item, (list, tuple)):
                if len(batch_item) == 2:
                    inputs, targets = batch_item
                    print(f"    ‚úì Strategy 3 (flexible): SUCCESS with 2 items")
                elif len(batch_item) == 1:
                    inputs = batch_item[0]
                    targets = None
                    print(f"    ‚úì Strategy 3 (flexible): SUCCESS with 1 item (no targets)")
                else:
                    print(f"    ‚ö†Ô∏è  Strategy 3: Unexpected length {len(batch_item)}")
            else:
                inputs = batch_item
                targets = None
                print(f"    ‚úì Strategy 3 (flexible): SUCCESS with single item")
        except Exception as e:
            print(f"    ‚ùå Strategy 3 (flexible): FAILED - {e}")
        
        # Only test first batch
        if batch_idx >= 2:
            break
    
    print(f"\n‚úÖ DataLoader diagnostic completed!")
    return True

def create_fixed_training_loop():
    """Create a robust training loop that handles the unpacking correctly."""
    
    code = '''
def robust_training_loop(model, train_loader, optimizer, criterion, device):
    """Robust training loop with proper DataLoader unpacking."""
    
    model.train()
    total_loss = 0
    batch_count = 0
    
    for batch_idx, batch_item in enumerate(train_loader):
        try:
            # ROBUST UNPACKING - handles all edge cases
            batch_inputs = None
            batch_targets = None
            
            if isinstance(batch_item, (list, tuple)):
                if len(batch_item) == 2:
                    # Standard case: (inputs, targets)
                    batch_inputs, batch_targets = batch_item
                elif len(batch_item) == 1:
                    # Only inputs
                    batch_inputs = batch_item[0]
                    batch_targets = None
                else:
                    print(f"‚ö†Ô∏è Unexpected batch format with {len(batch_item)} items")
                    continue
            else:
                # Single item
                batch_inputs = batch_item
                batch_targets = None
            
            # Validate we have both inputs and targets
            if batch_inputs is None or batch_targets is None:
                print(f"‚ö†Ô∏è Missing inputs or targets in batch {batch_idx}")
                continue
            
            # Move to device
            if isinstance(batch_inputs, dict):
                batch_inputs = {k: v.to(device) for k, v in batch_inputs.items()}
            else:
                batch_inputs = batch_inputs.to(device)
            batch_targets = batch_targets.to(device)
            
            # Standard training step
            optimizer.zero_grad()
            outputs = model(batch_inputs)
            
            # Handle model output format
            if isinstance(outputs, dict):
                pred = outputs['predictions']['horizon_1']
            else:
                pred = outputs
            
            # Handle target shapes
            if batch_targets.dim() > 1:
                target = batch_targets[:, 0]
            else:
                target = batch_targets
            
            # Ensure compatible shapes
            if pred.dim() > 1 and pred.size(1) > 1:
                pred = pred[:, 0]
            
            loss = criterion(pred.squeeze(), target.squeeze())
            
            # Check for valid loss
            if not torch.isfinite(loss):
                print(f"‚ö†Ô∏è Non-finite loss in batch {batch_idx}")
                continue
            
            loss.backward()
            
            # Gradient clipping
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)
            
            optimizer.step()
            
            total_loss += loss.item()
            batch_count += 1
            
            # Progress reporting
            if batch_idx % 25 == 0:
                print(f"Batch {batch_idx}: Loss={loss.item():.6f}, Grad_Norm={grad_norm:.6f}")
                
        except Exception as e:
            print(f"‚ùå Error in batch {batch_idx}: {e}")
            continue
    
    avg_loss = total_loss / max(batch_count, 1)
    print(f"Training completed: avg_loss={avg_loss:.6f}, processed_batches={batch_count}")
    return avg_loss
'''
    
    print("\nüìù Robust Training Loop Code:")
    print("=" * 50)
    print(code)
    
    return code

def main():
    """Main diagnostic function."""
    print("üöÄ TFT DataLoader Diagnostic & Fix")
    print("=" * 60)
    
    # Run diagnostics
    success = diagnose_dataloader()
    
    if success:
        print("\n‚úÖ DIAGNOSIS COMPLETE")
        print("\nThe DataLoader unpacking issue has been identified.")
        print("The training script has been updated with robust error handling.")
        
        # Provide the robust training loop
        create_fixed_training_loop()
        
        print("\nüí° RECOMMENDATION:")
        print("The training script now includes comprehensive error handling")
        print("that should resolve the 'too many values to unpack' error.")
        print("The script will now gracefully handle different batch formats.")
        
    else:
        print("\n‚ùå DIAGNOSIS FAILED")
        print("Please ensure PyTorch is installed and training data exists.")

if __name__ == "__main__":
    main()